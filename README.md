# Multi-agents based Research Topic Ideation System ğŸ”¬

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![Ollama](https://img.shields.io/badge/Ollama-Cloud%20Supported-orange.svg)](https://ollama.ai/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **Version 1.0**
>
> **Multi-Agent Research Ideation System: Generator â†’ Critic â†’ Refiner Loop**

An automated system that leverages **OpenAlex API** for real-time literature review and utilizes **Advanced LLMs (DeepSeek V3, GPT-OSS)** via Ollama Cloud to generate, critique, and refine **top-tier journal-quality** research proposals.

## âœ¨ Key Features

- **ğŸ” Smart Query Optimization**: Converts natural language intents into optimized search queries with exact phrase matching.
- **ğŸ”„ Keyword Combination Fallback**: When initial search returns <10 papers, automatically selects the best 2-keyword combination using LLM to expand the paper pool.
- **ğŸ“š Real-time Literature Review**: Fetches papers from **OpenAlex** (2020+) with deduplication.
- **ğŸ¤– Multi-Agent Pipeline**:
  - **Generator**: Uses **DeepSeek V3 (671B)** for idea generation with Chain of Thought.
  - **Critic**: Uses **GPT-OSS (120B)** to evaluate on Novelty, Feasibility, Specificity, and Impact.
  - **Refiner**: Uses **GPT-OSS (120B)** to improve ideas based on critique feedback.
- **â˜ï¸ Hybrid Operation**: Supports both **Local Ollama** and **Ollama Cloud**.
- **ğŸ“Š Rich Reports**: Auto-generates **Markdown** and **HTML** reports.

## ğŸ—ï¸ System Architecture

```mermaid
graph LR
    A[Natural Language Query] --> B[Query Optimizer]
    B --> C[3+ Keywords]
    C --> D[OpenAlex Search]
    D --> E{Papers >= 10?}
    E -->|Yes| G[Top-K Selection]
    E -->|No| F[LLM Selects Best 2 Keywords]
    F --> H[Secondary Search]
    H --> I[Merge & Deduplicate]
    I --> G
    G --> J[Generator Agent]
    J --> K[Critic Agent]
    K --> L{Score >= 3.0?}
    L -->|Yes| M[Accepted]
    L -->|2.0 - 3.0| N[Refiner Agent]
    L -->|< 2.0| O[Rejected]
    N --> K
    M --> P[Reports]
```

## ğŸ“ Project Structure

```text
â”œâ”€â”€ agents/                     # Agent Modules
â”‚   â”œâ”€â”€ base_agent.py           # Base agent class
â”‚   â”œâ”€â”€ generator.py            # Query optimization + Fallback + Idea generation
â”‚   â”œâ”€â”€ critic.py               # Evaluation logic
â”‚   â””â”€â”€ refiner.py              # Refinement logic
â”œâ”€â”€ core/                       # Core Infrastructure
â”‚   â”œâ”€â”€ model_manager.py        # Model loading & Cloud/Local management
â”‚   â”œâ”€â”€ mcp_client.py           # Context fetching
â”‚   â””â”€â”€ types.py                # Data types (IdeaObject, etc.)
â”œâ”€â”€ prompts/                    # System Prompts
â”‚   â”œâ”€â”€ generator.txt           # CoT + Critic-Solution Prompt
â”‚   â”œâ”€â”€ critic.txt              # Evaluation Rubric
â”‚   â””â”€â”€ refiner.txt             # Improvement Instructions
â”œâ”€â”€ utils/                      # Utilities
â”‚   â”œâ”€â”€ parser.py               # Robust JSON parsing
â”‚   â”œâ”€â”€ report_generator.py     # Markdown generation
â”‚   â””â”€â”€ html_generator.py       # HTML styling
â”œâ”€â”€ results/                    # Output Directory
â”œâ”€â”€ config.yaml                 # System Configuration
â”œâ”€â”€ main.py                     # Entry Point
â””â”€â”€ LICENSE                     # MIT License
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12+
- [Ollama](https://ollama.ai/) (Local or Cloud endpoint)

### Installation

```bash
git clone <repository-url>
cd 251212_Research_Ideation_Agent_with_MCP

pip install pyyaml requests
```

### Configuration

```yaml
openalex:
  fetch_limit: 200        # Papers to fetch per query
  top_k_papers: 10        # Top papers for context

agent_models:
  generator:
    provider: "ollama-cloud"
    model: "deepseek-v3.1:671b-cloud"
    temperature: 0.5

  critic:
    provider: "ollama-cloud"
    model: "gpt-oss:120b-cloud"
    temperature: 0.5

  refiner:
    provider: "ollama-cloud"
    model: "gpt-oss:120b-cloud"
    temperature: 0.5

loop_settings:
  max_iterations: 1
  num_ideas: 3
  score_threshold: 3.0
  drop_threshold: 2.0
```

### Usage

Input **natural language research intents**:

```bash
python main.py --keyword "I would like to advance my research on preventing thermal runaway in LFP-based ESS systems."
```

**Example Output:**

```
[generator] Optimized Query: '"thermal runaway prevention" "lithium iron phosphate" "energy storage systems"'
[generator] Found 5 papers from OpenAlex.
[generator] Found only 5 papers. Attempting keyword combination fallback...
[generator] Fallback Query: '"thermal runaway prevention" "lithium iron phosphate"'
[generator] After fallback: 15 unique papers in pool.
```

## ğŸ“Š Output

Results are saved in the `results/` directory:

1. **`research_results.json`**: Complete structured data including evolution history.
2. **`research_report_DATE.md`**: Readable report with scores and feedback.
3. **`research_report_DATE.html`**: Professional HTML report for sharing.

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

*Powered by DeepSeek V3 & GPT-OSS*
