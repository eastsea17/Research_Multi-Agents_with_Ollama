project:
  name: "Multi-agent based Research Topic Ideation System"
  version: "1.0"

hardware:
  memory_limit_gb: 24
  device: "mps" # Apple Silicon

ollama:
  base_url: "http://localhost:11434"  # Local Ollama instance
  cloud_url: "http://localhost:11434" # Ollama Cloud endpoint (configure as needed)

mcp_server:
  url: "http://localhost:8000"
  tools:
    - "openalex_search"
    - "vector_store_query"

openalex:
  fetch_limit: 200        # Number of papers to fetch from OpenAlex
  top_k_papers: 10         # Number of most relevant papers to use for idea generation

agent_models:
  generator:
    #provider: "ollama"
    #model: "deepseek-r1:14b"
    #temperature: 0.8
    #system_prompt_path: "./prompts/generator.txt"

    provider: "ollama-cloud"  # Ollama Cloud for better generating
    model: "deepseek-v3.1:671b-cloud"
    temperature: 0.5
    system_prompt_path: "./prompts/generator.txt"

  critic:
    provider: "ollama-cloud"  # Ollama Cloud for better reasoning
    model: "gpt-oss:120b-cloud"
    #model: "deepseek-v3.1:671b-cloud"
    temperature: 0.5
    system_prompt_path: "./prompts/critic.txt"

  refiner:
    provider: "ollama-cloud"
    model: "gpt-oss:120b-cloud" # Logic heavy
    temperature: 0.5
    system_prompt_path: "./prompts/refiner.txt"

loop_settings:
  max_iterations: 2
  num_ideas: 3            # Number of research ideas to generate
  score_threshold: 3.0
  drop_threshold: 2
